{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brain/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os.path\n",
    "from joblib import load, dump\n",
    "from nilearn.plotting import view_img_on_surf, view_img\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(id_layer):\n",
    "    title = \"conv{}_scores.pkl\"\n",
    "    filename = title.format(id_layer)\n",
    "    scores = load(filename)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_integrity_scores(id_layer) : \n",
    "    scores = load_scores(id_layer)\n",
    "    for n_neurons, neuron_scores in scores.items():\n",
    "        subject_list = []\n",
    "        for id_subject, score_vector in neuron_scores.items():\n",
    "            subject_list.append(id_subject)\n",
    "        if len(subject_list) < 16 :\n",
    "            print(\"Warning with {} neurons, layer {}\".format(n_neurons, id_layer))\n",
    "        else : \n",
    "            print(\"Layer {} for {} neurons has all the subjects\".format(id_layer, n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df():\n",
    "    df = pd.DataFrame()\n",
    "    for id_layer in range(5,8): \n",
    "        layer_scores = load_scores(id_layer)\n",
    "        index=['id_layer','id_subject', 'n_neurons', 'n_fold','r2_max']\n",
    "        for n_neurons, neuron_scores in layer_scores.items():\n",
    "            for id_subject, scores in neuron_scores.items():\n",
    "                for fold, score in enumerate(scores) :\n",
    "                    new_row = pd.Series([id_layer, id_subject, n_neurons, fold+1, score], index = index)\n",
    "                    df = df.append(new_row, ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'conv5_scores.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fb9f7312a25f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-1d68f7b463ae>\u001b[0m in \u001b[0;36mbuild_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mlayer_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_layer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id_subject'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_neurons'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_fold'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r2_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4014ae30d38d>\u001b[0m in \u001b[0;36mload_scores\u001b[0;34m(id_layer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"conv{}_scores.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conv5_scores.pkl'"
     ]
    }
   ],
   "source": [
    "df = build_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 6 for 1000 neurons has all the subjects\n",
      "Layer 7 for 1000 neurons has all the subjects\n"
     ]
    }
   ],
   "source": [
    "for id_layer in range(6,8) :\n",
    "    verify_integrity_scores(id_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  50.0   &  100.0  &  500.0  &  1000.0 &  1500.0 \\\\\n",
      "\\midrule\n",
      "0 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "1 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "2 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "3 &    0.00 &    0.01 &    0.02 &    0.03 &    0.03 \\\\\n",
      "4 &    0.11 &    0.13 &    0.13 &    0.13 &    0.14 \\\\\n",
      "5 &    0.11 &    0.11 &    0.12 &    0.12 &    0.12 \\\\\n",
      "6 &    0.14 &    0.18 &    0.26 &    0.28 &    0.28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Generate mean table \n",
    "table1_mean = pd.DataFrame()\n",
    "index = ['50','100','500','1000','1500']\n",
    "for id_layer in range(1,8):\n",
    "    layer = df[df.id_layer == id_layer]\n",
    "    f = layer.groupby('n_neurons').mean()['r2_max']\n",
    "    table1_mean = table1_mean.append(f,ignore_index = True)\n",
    "table1_mean.to_pickle(\"table1_mean.pkl\")\n",
    "print(table1_mean.to_latex(float_format=\"{:0.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  50.0   &  100.0  &  500.0  &  1000.0 &  1500.0 \\\\\n",
      "\\midrule\n",
      "0 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "1 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "2 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "3 &    0.02 &    0.03 &    0.04 &    0.04 &    0.05 \\\\\n",
      "4 &    0.08 &    0.08 &    0.08 &    0.08 &    0.08 \\\\\n",
      "5 &    0.07 &    0.07 &    0.07 &    0.07 &    0.07 \\\\\n",
      "6 &    0.15 &    0.15 &    0.13 &    0.13 &    0.12 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Generate std table \n",
    "table1_std = pd.DataFrame()\n",
    "index = ['50','100','500','1000','1500']\n",
    "for id_layer in range(1,8):\n",
    "    layer = df[df.id_layer == id_layer]\n",
    "    f = layer.groupby('n_neurons').std()['r2_max']\n",
    "    table1_std = table1_std.append(f,ignore_index = True)\n",
    "table1_std.to_pickle(\"table1_std.pkl\")\n",
    "print(table1_std.to_latex(float_format=\"{:0.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  50.0   &  100.0  &  500.0  &  1000.0 &  1500.0 \\\\\n",
      "\\midrule\n",
      "0 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "1 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "2 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "3 &    0.01 &    0.01 &    0.01 &    0.01 &    0.01 \\\\\n",
      "4 &    0.02 &    0.02 &    0.02 &    0.02 &    0.02 \\\\\n",
      "5 &    0.02 &    0.02 &    0.02 &    0.02 &    0.02 \\\\\n",
      "6 &    0.04 &    0.04 &    0.03 &    0.03 &    0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Generate stderr table\n",
    "import numpy as np\n",
    "table1_stderr = table1_std/np.sqrt(16)\n",
    "table1_stderr.to_pickle(\"table1_stderr.pkl\")\n",
    "print(table1_stderr.to_latex(float_format=\"{:0.2f}\".format))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  50.0   &  100.0  &  500.0  &  1000.0 &  1500.0 \\\\\n",
      "\\midrule\n",
      "0 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "1 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "2 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "3 &    0.19 &    0.15 &    0.15 &    0.18 &    0.21 \\\\\n",
      "4 &    0.27 &    0.31 &    0.33 &    0.34 &    0.31 \\\\\n",
      "5 &    0.27 &    0.24 &    0.23 &    0.25 &    0.28 \\\\\n",
      "6 &    0.43 &    0.48 &    0.50 &    0.53 &    0.48 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Generate max table\n",
    "table1_max = pd.DataFrame()\n",
    "index = ['50','100','500','1000','1500']\n",
    "for id_layer in range(1,8):\n",
    "    layer = df[df.id_layer == id_layer]\n",
    "    f = layer.groupby('n_neurons').max()['r2_max']\n",
    "    table1_max = table1_max.append(f,ignore_index = True)\n",
    "table1_max.to_pickle(\"table1_max.pkl\")\n",
    "print(table1_max.to_latex(float_format=\"{:0.2f}\".format))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  50.0   &  100.0  &  500.0  &  1000.0 &  1500.0 \\\\\n",
      "\\midrule\n",
      "0 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "1 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "2 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "3 &    0.00 &    0.00 &    0.00 &    0.00 &    0.00 \\\\\n",
      "4 &    0.00 &    0.01 &    0.01 &    0.02 &    0.02 \\\\\n",
      "5 &    0.01 &    0.02 &    0.01 &    0.01 &    0.01 \\\\\n",
      "6 &    0.00 &    0.00 &    0.00 &    0.00 &    0.04 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Generate min table\n",
    "table1_min = pd.DataFrame()\n",
    "index = ['50','100','500','1000','1500']\n",
    "for id_layer in range(1,8):\n",
    "    layer = df[df.id_layer == id_layer]\n",
    "    f = layer.groupby('n_neurons').min()['r2_max']\n",
    "    table1_min = table1_min.append(f,ignore_index = True)\n",
    "table1_min.to_pickle(\"table1_min.pkl\")\n",
    "print(table1_min.to_latex(float_format=\"{:0.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate table of mean(r2_max) accross folds \n",
    "table2 = pd.DataFrame()\n",
    "index = ['1','2','3','4']\n",
    "for id_layer in range(5,8):\n",
    "    layer = df[df.id_layer == id_layer]\n",
    "    f = layer.groupby('n_fold').mean()['r2_max']\n",
    "    table2 = table2.append(f,ignore_index = True)\n",
    "table2.to_pickle(\"table2.pkl\")\n",
    "print(table2.to_latex(float_format=\"{:0.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the number of the best fold per subject per layer\n",
    "table3 = pd.DataFrame()\n",
    "index = ['conv5', 'conv6', 'conv7']\n",
    "df_alias = df[df.n_neurons == 1000]\n",
    "a = []\n",
    "for id_subject in range(1,18):\n",
    "    if id_subject != 5 :\n",
    "        arr_subject = []\n",
    "        for id_layer in range(5,8):\n",
    "            layer = df_alias[df_alias.id_layer == id_layer]\n",
    "            subject = layer[layer.id_subject == id_subject][['r2_max']]\n",
    "            best_fold = subject.to_numpy().argmax() + 1\n",
    "            if best_fold == 0:\n",
    "                print(id_layer, id_subject)\n",
    "            arr_subject.append(best_fold)\n",
    "        a.append(arr_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_fold.pkl']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np = np.array(a)\n",
    "dump(a_np, 'best_fold.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 0, 6, 23)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un, d, t,q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
