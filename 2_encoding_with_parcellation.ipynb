{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nilearn imports\n",
    "from nilearn.plotting import plot_roi, plot_stat_map, plot_anat\n",
    "from nilearn.image import mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path\n",
    "from joblib import dump, load\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the differents path to data and folders\n",
    "\n",
    "# path to **PREPROCESSED** dataset of Sherlock or Merlin\n",
    "local_sherlock_path = \"/home/brain/datasets/SherlockMerlin_ds001110/\"\n",
    "\n",
    "# locate the folder containing feature vectors extracted from soundnet for the corresponding movie (merlin_pytorch or sherlock_pytorch\n",
    "feature_folder = \"soundnet_features/sherlock_pytorch/\"\n",
    "\n",
    "# folder for storing the resulting r2 brain maps\n",
    "result_folder = \"results/parcellation_conv{}/\"\n",
    "\n",
    "# path to mask files (make sure to match the naming convention)\n",
    "### WARNING : be sure to write the mask corresponding to the task (MerlinMovie or SherlockMovie)\n",
    "generic_mask_name = \"/home/brain/datasets/SherlockMerlin_ds001110/sub-{:02d}/func/sub-{:02d}_task-SherlockMovie_bold_space-T1w_brainmask.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'results/parcellation_conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-58e2854e0642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#os.mkdir(\"results\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/parcellation_conv{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'results/parcellation_conv1'"
     ]
    }
   ],
   "source": [
    "# generate folders for organized storage\n",
    "os.mkdir(\"fmri_mean\")\n",
    "os.mkdir(\"wards\")\n",
    "os.mkdir(\"fmri_ready\")\n",
    "os.mkdir(\"results\")\n",
    "for id_layer in range(1,8):\n",
    "    os.mkdir(\"results/parcellation_conv{}\".format(id_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define utility functions\n",
    "\n",
    "Used to load data more efficiently and in a modular manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcellate(id_subject, n_frames):\n",
    "    # Compute the ward parcellation and other fmri data of a given subject and save it\n",
    "    \n",
    "    # Function should be called only when the feature vector or number of parcels change\n",
    "    from nilearn.regions import Parcellations\n",
    "    from nilearn.input_data import NiftiMasker\n",
    "    ### Load fmri data\n",
    "    filename = \"sub-{:02d}_task-SherlockMovie_bold_space-T1w_preproc.nii.gz\".format(id_subject)\n",
    "    folder_name = \"sub-{:02d}/func\".format(id_subject)\n",
    "    irm_file = os.path.join(local_sherlock_path,folder_name, filename)\n",
    "    fmri_mean = mean_img(irm_file)\n",
    "    fmri_mean.to_filename(\"fmri_mean/sub-{:02d}.nii.gz\".format(id_subject))\n",
    "    print(\"Saved mean fmri for subject {}\".format(id_subject))\n",
    "    \n",
    "    ### Compute mask\n",
    "    filename_mask = generic_mask_name.format(id_subject,id_subject)\n",
    "    masker = NiftiMasker(mask_img=filename_mask, detrend=True,standardize=True)\n",
    "    masker.fit()\n",
    "    ward = Parcellations(method='ward',mask=masker,standardize=True,smoothing_fwhm=None,n_parcels=500)\n",
    "    ward.fit(irm_file)\n",
    "    dump(ward, \"wards/sub-{:02d}.nii.gz\".format(id_subject))\n",
    "    print(\"Saved ward mask for subject {}\".format(id_subject))\n",
    "    \n",
    "    # Compute fmri_ready\n",
    "    fmri_data = ward.transform(irm_file)\n",
    "    # Truncate the data because of an offset in the fmri (see dataset description)\n",
    "    fmri_ready = fmri_data[17:-(fmri_data.shape[0]-17-n_frames)]  \n",
    "    np.save(\"fmri_ready/sub-{:02d}\".format(id_subject), fmri_ready)    \n",
    "    print(\"Saved fmri_ready for subject {}\".format(id_subject))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_vector(id_layer) :\n",
    "    filename = \"conv{}.npz\".format(id_layer)\n",
    "    file_fv = os.path.join(feature_folder, filename)\n",
    "    fv = np.load(file_fv)['fv']\n",
    "    # Check the size\n",
    "    n_frames = fv.shape[0]\n",
    "    print(\"layer {}, {} frames, FV dimension is {}\".format(id_layer,n_frames, fv.shape[1]))\n",
    "    return fv, n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fmri_data(id_subject):\n",
    "    from nilearn.input_data import NiftiLabelsMasker\n",
    "    fmri_ready = np.load(\"fmri_ready/sub-{:02d}.npy\".format(id_subject))\n",
    "    fmri_mean = \"fmri_mean/sub-{:02d}.nii.gz\".format(id_subject)\n",
    "    ward = load(\"wards/sub-{:02d}.nii.gz\".format(id_subject))\n",
    "    return fmri_ready, fmri_mean, ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(id_layer,id_subject): \n",
    "    X, _ = load_feature_vector(id_layer)\n",
    "    y, fmri_mean, ward = load_fmri_data(id_subject)\n",
    "    return X, y, fmri_mean, ward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation :\n",
    "We first have to pre-generate the data  that we will use repeatedly. \n",
    "We need the length of the feature vector to do so, which is why we use the corresponding function.\n",
    "We then proceed to generating all the needed data, one subject at a time.\n",
    "\n",
    "--- It should be noted that we do not have data for subject 5, which is why it is consistently skipped ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_frames = load_feature_vector(7)\n",
    "for id_subject in range(1,18):\n",
    "    if id_subject != 5 :\n",
    "        parcellate(id_subject, n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition :\n",
    "We use an MLP on multiple folds, with early stopping enabled, and only one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, fmri_mean, ward, n_folds,id_layer, id_subject, alpha=0.0001, n_neurons = 1000, plot=False):\n",
    "    print(\"Training on subject {} and layer {} with {} folds and alpha = {}\".format(id_subject, id_layer, n_folds, alpha))\n",
    "    mlp_estimator = MLPRegressor(hidden_layer_sizes=(n_neurons,),solver='adam',activation='relu',\n",
    "                             max_iter=2000,learning_rate_init=0.001, alpha=alpha, \n",
    "                             batch_size=50,early_stopping=True,verbose=False, warm_start = False)\n",
    "    cv = KFold(n_splits = n_folds)\n",
    "    fold_number = 1\n",
    "    scores = []\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        print(\"Subject {} Fold {},layer {} index = [{},{}], alpha={},neurons={} :\".format(id_subject,fold_number,id_layer, test_index[0], test_index[-1], alpha, n_neurons))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # warm_start is False so each train is fitted on a new MLP\n",
    "        mlp_estimator.fit(X_train, y_train) \n",
    "        predictions = mlp_estimator.predict(X_test)\n",
    "        # Compare predictions and truth, using the r2 metric\n",
    "        r2_scores = r2_score(y_test, predictions, multioutput=\"raw_values\")\n",
    "        r2_scores[r2_scores < 0 ] = 0\n",
    "        r2_max = np.max(r2_scores)\n",
    "        print(r2_max)\n",
    "        # Generate corresponding mapping with the brain\n",
    "        scores_img = ward.inverse_transform(r2_scores.reshape((1,-1)))\n",
    "        scores_img.to_filename(\"./{}/fold{}_sub{:02d}alpha{}_{}neurons.nii.gz\".format(layer_result_folder, fold_number, id_subject,alpha, n_neurons))\n",
    "        \n",
    "        if plot :\n",
    "            plot_stat_map(scores_img,bg_img=fmri_mean, title = \"{} neurons fold{} sub{:02d} alpha{}\".format(n_neurons,fold_number, id_subject, alpha))\n",
    "            plt.savefig(\"./{}/{}neurons_fold{}_sub{:02d}alpha{}_.png\".format(layer_result_folder, n_neurons,fold_number, id_subject, alpha))\n",
    "            plt.show()\n",
    "        fold_number += 1\n",
    "        scores.append(r2_max)\n",
    "    # scores is a list of length n_folds ,the  i-th element is the max r2 score (accross 500 parcels) for the i-th fold\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "\n",
    "hidden_layer_sizes = [100,500,1000]\n",
    "n_folds = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_layer in range(5,8):\n",
    "    #layer1-3 give non-significant results (10e-5)\n",
    "    # layer4 gives bigger results but still insignificant\n",
    "    print(\"Layer #{}\".format(id_layer))\n",
    "    layer_result_folder = result_folder.format(id_layer)\n",
    "    filename = \"conv{}_scores.pkl\".format(id_layer)\n",
    "    if filename in os.listdir(\".\") :\n",
    "        layer_scores = load(filename)\n",
    "    else: \n",
    "        layer_scores = {}\n",
    "    for n_neurons in hidden_layer_sizes :\n",
    "        print(\"Neurons {}\".format(n_neurons))\n",
    "        if n_neurons in layer_scores.keys():\n",
    "            neurons_scores = layer_scores[n_neurons]\n",
    "        else :\n",
    "            neurons_scores = {}\n",
    "        for id_subject in tqdm.tqdm(range(1,18)):\n",
    "            print(\"Subject {}\".format(id_subject))\n",
    "            if id_subject != 5 :\n",
    "                X, y, fmri_mean, ward = load_data(id_layer,id_subject)\n",
    "                r2_scores = train(X, y, fmri_mean, ward, n_folds, id_layer, id_subject,0.0001, n_neurons)\n",
    "            neurons_scores[id_subject] = list(r2_scores)\n",
    "        layer_scores[n_neurons] = dict(neurons_scores)\n",
    "        dump(layer_scores,filename) # The scores are stored in a dictionnary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
